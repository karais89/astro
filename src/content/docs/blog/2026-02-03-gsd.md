---
title: "Get Shit Done (GSD) 써보니 - 사용 후기"
description: "GSD(get-shit-done-cc)로 SDD 스타일 워크플로우를 돌려봤지만, 느린 속도와 큰 오버헤드에 막혔던 솔직 후기"
date: 2026-02-03
tags: ["AI", "GSD", "SDD", "OpenCode"]
draft: false
template: splash
related:
  - href: "https://github.com/glittercowboy/get-shit-done"
    label: "get-shit-done GitHub"
  - href: "/blog/2026-01-28-openspec/"
    label: "OpenSpec 후기"
---

## 들어가며

2026년 2월 3일, 새 프로젝트를 시작해보려고 **GSD(get-shit-done-cc)** 를 만져봤다.

왜 이런 류의 도구가 나오는지, 그리고 어떤 지점에서 “오버헤드”가 생기는지 정도는 꽤 체감할 수 있었어서 삽질 기록을 남긴다.

> TL;DR
>
> - 스펙 주도(SDD) 방식으로 “질문 → 문서 → 실행 → 검증”을 강하게 밀어붙이는 도구
> - 멀티 에이전트가 돌아가긴 하는데, 체감 속도는 기대만큼 빠르지 않았다
> - 작은 기능/토이 프로젝트에는 오버헤드가 크고, 모델/환경에 따라 대기 시간이 크게 달라질 수 있다

---

## GSD는 뭐 하는 도구인가?

[GSD(get-shit-done)](https://github.com/glittercowboy/get-shit-done)는 Open Spec과 비슷하게 **문서(요구사항/로드맵/상태)를 “진실의 원천(Source of Truth)”으로 두고** 그 문서를 기준으로 AI가 작업을 진행하도록 만드는 워크플로우 툴이다.

(내가 느낀 핵심은) “코드를 바로 치기보다, 먼저 설계/계획을 강제해서 사고를 정리하게 만든다”는 점이다.

GSD가 해결하려는 문제는 README에서 말하는 **context-rot**에 가깝다. 대화가 길어질수록 컨텍스트 윈도우가 오염(?)되면서 품질이 떨어지는 상황을, **문서+상태+작은단위실행(서브에이전트)** 로 버티는 방식이다.

---

## 관련 자료(공식/참고)

글을 쓰다 보니 내 체험만으로는 설명이 빈약한 부분이 있어서, 공식 문서를 같이 참고하면 이해가 빨라진다.

- 공식 GitHub: [glittercowboy/get-shit-done](https://github.com/glittercowboy/get-shit-done)
  - 설치 방법, 권한 설정, 그리고 주요 명령어 흐름이 정리되어 있음
  - 이 글의 커맨드/산출물 설명은 README를 기준으로 정리했음
  - 실제 제공되는 커맨드/옵션은 `/gsd:help`가 최종 기준
- 공식 사이트: [gsd.site](https://gsd.site/)
  - “왜 GSD인가 / 어떻게 동작하나”를 빠르게 훑기 좋음

---

## 설치 / 업데이트

```sh
npx get-shit-done-cc
```

![GSD 설치 화면](./_assets/2026-02-03-gsd-1.png)

업데이트는 아래처럼.

```sh
npx get-shit-done-cc@latest
```

설치가 제대로 되었는지, 그리고 현재 환경에서 어떤 명령이 제공되는지는(클라이언트/버전별로 차이가 있을 수 있어서) 아래로 확인하는 게 제일 확실하다.

```text
/gsd:help
```

README 기준으로는 설치 시 다음을 고른다:

1. Runtime(Claude Code / OpenCode / Gemini CLI / All)
2. Location(Global / Local)

특히 스크립트/CI/Docker 같은 비대화형 환경에서는 런타임/설치 위치를 옵션으로 고정할 수 있다:

```sh
# Claude Code
npx get-shit-done-cc --claude --global
npx get-shit-done-cc --claude --local

# OpenCode
npx get-shit-done-cc --opencode --global
npx get-shit-done-cc --opencode --local

# Gemini CLI
npx get-shit-done-cc --gemini --global
```

---

## 권한 철학: 일단 다 허용하자?

GSD 쪽 철학은 “모든 권한을 허용하는 게 맞다”에 가까운 느낌이었다.

예를 들어 Claude Code 쪽은 이런 식으로(주의!) 권한 스킵 모드를 쓰는 흐름이 있다.

```sh
claude --dangerously-skip-permissions
```

만약 권한 스킵이 부담된다면, README에는 프로젝트의 `.claude/settings.json`에 granular permissions를 등록하는 대안도 소개되어 있다.

반면 OpenCode는(내가 확인한 범위에선) “YOLO 모드” 같은 원클릭이 없어서 `opencode.json`을 아래처럼 손대서 권한을 넓혀주는 방식이 있는 듯하다.

```json
{
  "permission": {
    "*": {
      "*": "allow"
    }
  }
}
```

> 보안/안전 관점에서는 당연히 리스크가 있으니, 개인 프로젝트/격리된 환경에서만 신중하게 쓰는 게 좋다.

---

## 기본 워크플로우(공식 README 요약)

> 실제 커맨드/옵션은 `/gsd:help`가 최종 기준이고, 아래는 README 흐름을 “요약”한 것이다.

이미 코드가 있는 경우(선행 후 프로젝트 초기화):

```text
/gsd:map-codebase
```

새 프로젝트인 경우:

1) 프로젝트 초기화

```text
/gsd:new-project
```

README에서 설명하는 `/gsd:new-project`의 흐름은 대략 아래 순서다:

1. Questions — 목표/제약/기술 선호/엣지 케이스까지 “이해될 때까지” 질문
2. Research — (선택) 도메인 조사를 병렬 서브 에이전트로 수행
3. Requirements — v1/v2/범위 밖을 추출
4. Roadmap — Requirements를 phase로 나누어 로드맵 작성

그리고 아래 파일들이 생성된다고 한다:

- `PROJECT.md`
- `REQUIREMENTS.md`
- `ROADMAP.md`
- `STATE.md`
- `.planning/research/`

2) 논의 단계(phase별 구현 선호/결정 수집)

```text
/gsd:discuss-phase 1
```

이 단계는 README에서 “내가 상상하는 구현”을 잡아주는 단계로 설명한다. UI/CLI/API/콘텐츠 시스템 등, 회색지대를 질문으로 메꿔서 `{phase}-CONTEXT.md`를 만들고, 이게 다음 단계(리서치/플랜)에 입력으로 들어간다.

**Creates:** `{phase}-CONTEXT.md`

3) 계획 단계(리서치 + 플랜 생성 + 검증)

```text
/gsd:plan-phase 1
```

README 기준 산출물:

- **Creates:** `{phase}-RESEARCH.md`, `{phase}-{N}-PLAN.md`

4) 실행 단계(플랜 실행 + 커밋 + 검증)

```text
/gsd:execute-phase 1
```

README에서 강조하는 포인트:

- 플랜을 “wave”로 돌리되, 가능한 건 병렬로 실행
- 플랜 단위로 컨텍스트를 새로 열어서(누적 대화 오염을 줄임) 구현 품질을 유지
- 태스크 단위로 atomic commit을 남김(히스토리/되돌리기/추적에 유리)

README 기준 산출물:

- **Creates:** `{phase}-{N}-SUMMARY.md`, `{phase}-VERIFICATION.md`

5) 작업 검증(UAT)

```text
/gsd:verify-work 1
```

- 작업을 테스트 하고, 수동 테스트가 필요시 한 단계 씩 수동 테스트를 확인 후 진행하는 방식이 인상 깊었다.

**Creates:** `{phase}-UAT.md` (문제가 있으면 수정 플랜도 생성)

6) 반복 / 마일스톤

```text
/gsd:discuss-phase 2
/gsd:plan-phase 2
/gsd:execute-phase 2
/gsd:verify-work 2

/gsd:complete-milestone
/gsd:new-milestone
```

수정 계획/수정만 실행하는 옵션도 있는 듯했다:

```text
/gsd-plan-phase 1 --gaps
/gsd-execute-phase 1 --gaps-only
```

---

## Quick Mode(간단 작업용)

README에는 “풀 워크플로우가 과한” 버그픽스/자잘한 설정 변경을 위한 모드도 있다.

```text
/gsd:quick
```

phase 플로우(논의/계획/검증)를 스킵하고도, 문서 추적과 커밋 단위 같은 GSD 성격은 유지하는 방식이다.

---

## 내가 시도한 것(그리고 막힌 지점)

### 1) 테스트 환경(클라이언트/모델)

- OpenCode로 실행
- Kimi k2.5 모델로 테스트
- GPT 5.2 모델로 테스트

> 성능 비교가 글의 주제는 아니라서, “무슨 환경에서 돌렸는지” 정도만 남긴다.

### 2) “문서는/응답은 무조건 한글” 강제

`project.md`, `config.js` 같은 곳에 아래 규칙을 박아 넣어봤다.

```text
<!--
🚨 중요 규칙(절대 위반 금지)

1) 모든 플래닝 문서는 한국어로 작성한다
   - 적용: 이 파일, REQUIREMENTS.md, ROADMAP.md, STATE.md, .planning/ 아래 모든 파일
   - 예외: 기술 용어, 코드, 파일 경로, REQ-ID

2) 모든 AI 응답은 한국어로 작성한다
   - 포함: 설명, 질문, 요약, 모든 사용자 노출 출력
   - 예외: 기술 용어, 코드 스니펫

위 규칙을 위반한 산출물은 무효로 간주하고 한국어로 다시 작성한다.
-->
```

설정(JSON)도 비슷한 취지로 넣었다.

```json
{
  "language": {
    "code": "ko",
    "name": "한국어",
    "priority": "critical",
    "enforced": true,
    "document_rule": "모든 플래닝 문서는 한국어로 작성한다. 예외: 기술 용어, 코드, 파일 경로, REQ-ID",
    "response_rule": "모든 AI 응답은 한국어로 작성한다. 포함: 설명, 질문, 요약, 모든 사용자 노출 출력. 예외: 기술 용어, 코드 스니펫"
  }
}
```

### 3) 질문 공세(리서치)가 정말 길다

`/gsd:new-project` 한 번 돌렸을 뿐인데, “간단한 TODO 앱” 수준에서도 질문이 꽤 길게 이어졌다.

근데 이게 마냥 부정적이진 않았다. 오히려 “내가 대충 알고 있던 걸 문장으로 강제”해서,
처음에 허술했던 요구사항을 보완하는 데 도움이 됐다.

아래 스크린샷들은 모두 `/gsd:new-project` 실행 직후, 요구사항을 구체화하기 위한 “인터뷰” 구간이다.

![GSD 질문 인터뷰 (1)](./_assets/2026-02-03-gsd-2.png)
![GSD 질문 인터뷰 (2)](./_assets/2026-02-03-gsd-3.png)
![GSD 질문 인터뷰 (3)](./_assets/2026-02-03-gsd-4.png)

### 4) 플랜/실행 단계가 느리다

- `/gsd:plan-phase 1`도 시간이 오래 걸림
- `/gsd:execute-phase 1`도 오래 걸림
- 토큰 소비가 크고, 오래 걸린다는 얘기가 이해가 됨

특히 자체적으로 서브 에이전트를 5개 정도 돌리는 것 같은데, “병렬이면 빨라야 하는 거 아닌가?”라는 의문이 생겼다.

---

## 왜 느렸을까? (개인 가설)

정확한 원인 분석은 못 했지만, 체감상 가능성은 몇 가지가 있다.

- **모델/서버 대기열**: 인기/free 모델일수록 응답 지연이 커지는 느낌
- **멀티 에이전트 오버헤드**: 병렬로 돌려도 "합치고 정리하는" 단계가 길면 결국 느려짐
- **리서치 기본값이 과함**: 작은 프로젝트에도 "과잉 탐색"이 들어가서 시간/토큰이 크게 나감
- **작업을 쪼개서 확정하는 UX**: verify 단계에서 `pass`를 반복 입력하는 흐름이 에디터/클라이언트에 따라 번거로울 수 있음

---

## OpenSpec과 비교

예전에 써본 OpenSpec과 비교하면 다음과 같다(내 체감 기준).

| 항목 | OpenSpec | GSD |
|------|----------|-----|
| **워크플로우** | 단순<br>`/opsx:new` → `/opsx:ff` → 문서 수정 → `/opsx:apply` | 복잡<br>discuss → plan → execute → verify + 마일스톤 반복 |
| **체감 속도** | 빠름 | 느림 (멀티 에이전트 오버헤드) |
| **문서화 강도** | 중간 | 높음 (phase별 다수 문서 생성) |
| **적합한 규모** | 작은~중간 기능, 토이 프로젝트 | 중간~큰 프로젝트, 팀 협업 |
| **프로세스 느낌** | 캐주얼 | 진지한 프로세스 |

“진지하게 일하는 팀”에는 GSD가 맞을 수도 있지만, 혼자 토이 프로젝트/작은 기능을 할 때는 오버헤드가 크게 느껴질 수 있다.

관련해서 OpenSpec은 따로 글로 정리해둠: [OpenSpec 써보니](../2026-01-28-openspec/)

---

## 마무리: 다음에 다시 해본다면

속도가 느렸지만, 방향성은 꽤 마음에 들었다. 다음에 다시 시도한다면 이렇게 해볼 것 같다.

- **마일스톤/스코프를 더 작게**: "TODO 앱 전체" 말고 "로그인 화면 1개" 같은 단위로
- **리서치 범위 줄이기**: 질문이 과하면, 답을 더 단단하게(스펙을 선제공)
- **verify 단계 운영 방식 고민**: 내가 쓰는 클라이언트에서 UX가 맞는지

추가로, 현재는 아래를 더 확인 중이다.

- Claude Code로도 돌려보고 속도를 비교하는 중
- Unity 프로젝트(게임 개발)에도 이 워크플로우가 어울리는지 테스트 필요

나처럼 “큰 성과는 없었는데, 왜 느린지 궁금해서 만져봤다” 같은 사람에게는 삽질 자체가 학습이 되는 도구였다. 다만, 당장 업무에 투입하기엔 속도/비용이 관건.
